{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ba5d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayan.banerjee/python-3.13.7/lib/python3.13/site-packages/lightkurve/prf/__init__.py:7: UserWarning: Warning: the tpfmodel submodule is not available without oktopus installed, which requires a current version of autograd. See #1452 for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701b2a658b4a48c8af92f505fbbab3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/1000 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's auc: 1\tvalid's auc: 0.794576\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttrain's auc: 0.999776\tvalid's auc: 0.96339\n",
      "\n",
      "=== Evaluation ===\n",
      "Accuracy: 0.9833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9833    1.0000    0.9916       295\n",
      "           1     0.0000    0.0000    0.0000         5\n",
      "\n",
      "    accuracy                         0.9833       300\n",
      "   macro avg     0.4917    0.5000    0.4958       300\n",
      "weighted avg     0.9669    0.9833    0.9751       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayan.banerjee/python-3.13.7/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/rayan.banerjee/python-3.13.7/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/rayan.banerjee/python-3.13.7/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c380733e71a448688beefb70a8b9e2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Greedy attack:   0%|          | 0/200 [00:00<?, ?iter/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adversarial Attack Result ===\n",
      "Original pred: 0 (p1=0.0102)  →  Desired: 1\n",
      "After attack:  1 (p1=0.5024)  | Success: True\n",
      "\n",
      "Changed features (feature_name : delta [percent of (max-min)]):\n",
      " - frac_nan    : -0.0158854  [-88.79% of range]\n",
      " - ac1         : -0.849478  [-83.60% of range]\n",
      " - rms         : -0.00262563  [-9.49% of range]\n",
      " - mad         : -0.00198986  [-7.20% of range]\n",
      " - p5          : +0.00376532  [+8.54% of range]\n",
      " - p95         : -0.00477912  [-12.31% of range]\n",
      " - amp         : -0.00856087  [-10.91% of range]\n",
      "\n",
      "Top feature importances (gain):\n",
      " 1. ac1          : 208.864\n",
      " 2. amp          : 143.045\n",
      " 3. p95          : 102.274\n",
      " 4. mean         : 74.124\n",
      " 5. rms          : 69.020\n",
      " 6. mad          : 65.005\n",
      " 7. p5           : 64.006\n",
      " 8. frac_nan     : 14.697\n",
      " 9. slope        : 13.076\n",
      "10. kurt         : 3.513\n"
     ]
    }
   ],
   "source": [
    "# === Kepler Light Curves → Features → LightGBM → Adversarial Attack (with tqdm) ===\n",
    "import os, sys, warnings, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import lightkurve as lk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import lightgbm as lgb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "DATA_FOLDER = Path(\"kepler_lightcurves/lightcurves_all/kepler\")  # change if needed\n",
    "MANIFEST_CSV = Path(\"data/kepler_lightcurves/kepler_local_lightcurves_status.csv\")  # your manifest\n",
    "MAX_FILES = 1000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# --------------------------\n",
    "# Helpers: robust feature engineering from a light curve\n",
    "# --------------------------\n",
    "def robust_stats(flux):\n",
    "    f = flux[np.isfinite(flux)]\n",
    "    if f.size == 0:\n",
    "        return dict(mean=np.nan, std=np.nan, mad=np.nan, p5=np.nan, p95=np.nan,\n",
    "                    amp=np.nan, skew=np.nan, kurt=np.nan)\n",
    "    mean = float(np.mean(f))\n",
    "    std = float(np.std(f))\n",
    "    med = float(np.median(f))\n",
    "    mad = float(np.median(np.abs(f - med)))\n",
    "    p5, p95 = float(np.percentile(f, 5)), float(np.percentile(f, 95))\n",
    "    amp = p95 - p5\n",
    "    if std > 0:\n",
    "        z = (f - mean) / std\n",
    "        skew = float(np.mean(z**3))\n",
    "        kurt = float(np.mean(z**4) - 3.0)  # Fisher\n",
    "    else:\n",
    "        skew = 0.0\n",
    "        kurt = -3.0\n",
    "    return dict(mean=mean, std=std, mad=mad, p5=p5, p95=p95, amp=amp, skew=skew, kurt=kurt)\n",
    "\n",
    "def lin_slope(time, flux):\n",
    "    mask = np.isfinite(time) & np.isfinite(flux)\n",
    "    t, f = time[mask], flux[mask]\n",
    "    if t.size < 5:\n",
    "        return np.nan\n",
    "    t0 = (t - t.mean()) / (t.std() + 1e-12)\n",
    "    coeffs = np.polyfit(t0, f, 1)\n",
    "    return float(coeffs[0])\n",
    "\n",
    "def lag1_autocorr(x):\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size < 3:\n",
    "        return np.nan\n",
    "    x0, x1 = x[:-1], x[1:]\n",
    "    s0, s1 = np.std(x0), np.std(x1)\n",
    "    if s0 == 0 or s1 == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x0, x1)[0, 1])\n",
    "\n",
    "def extract_features_from_fits(path: Path):\n",
    "    \"\"\"Read a Kepler lightcurve FITS and return a dict of engineered features.\"\"\"\n",
    "    try:\n",
    "        lc_obj = lk.read(path)  # KeplerLightCurve (usually)\n",
    "        if hasattr(lc_obj, \"pdcsap_flux\") and lc_obj.pdcsap_flux is not None:\n",
    "            time = np.asarray(lc_obj.time.value, dtype=float)\n",
    "            flux = np.asarray(lc_obj.pdcsap_flux.value, dtype=float)\n",
    "        elif hasattr(lc_obj, \"flux\") and lc_obj.flux is not None:\n",
    "            time = np.asarray(lc_obj.time.value, dtype=float)\n",
    "            flux = np.asarray(lc_obj.flux.value, dtype=float)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported LightCurve object (no flux field).\")\n",
    "    except Exception:\n",
    "        # Raw FITS fallback\n",
    "        with fits.open(path, memmap=False) as hdul:\n",
    "            data = hdul[1].data\n",
    "            time = np.asarray(data[\"TIME\"], dtype=float)\n",
    "            if \"PDCSAP_FLUX\" in data.names:\n",
    "                flux = np.asarray(data[\"PDCSAP_FLUX\"], dtype=float)\n",
    "            elif \"SAP_FLUX\" in data.names:\n",
    "                flux = np.asarray(data[\"SAP_FLUX\"], dtype=float)\n",
    "            else:\n",
    "                raise RuntimeError(f\"No PDCSAP_FLUX/SAP_FLUX in {path.name}\")\n",
    "\n",
    "    mask = np.isfinite(time) & np.isfinite(flux)\n",
    "    if mask.sum() == 0:\n",
    "        raise RuntimeError(f\"No finite flux/time in {path.name}\")\n",
    "\n",
    "    # Keep only valid\n",
    "    time, flux = time[mask], flux[mask]\n",
    "\n",
    "    # Relative flux\n",
    "    med = np.median(flux)\n",
    "    rel = (flux / (med if med != 0 else 1.0)) - 1.0\n",
    "\n",
    "    stats = robust_stats(rel)\n",
    "    n = int(rel.size)\n",
    "    frac_nan = float(1.0 - (mask.sum() / len(mask))) if len(mask) > 0 else 0.0\n",
    "    slope = lin_slope(time, rel)\n",
    "    ac1 = lag1_autocorr(rel)\n",
    "    rms = float(np.sqrt(np.mean((rel - np.median(rel))**2)))\n",
    "\n",
    "    feats = dict(\n",
    "        n_cadences=n,\n",
    "        frac_nan=frac_nan,\n",
    "        slope=slope,\n",
    "        ac1=ac1,\n",
    "        rms=rms,\n",
    "        **stats,\n",
    "    )\n",
    "    return feats\n",
    "\n",
    "# --------------------------\n",
    "# Load manifest (labels) and collect FITS paths\n",
    "# --------------------------\n",
    "fits_files = sorted(DATA_FOLDER.glob(\"**/*.fits\"))[:MAX_FILES]\n",
    "if len(fits_files) == 0:\n",
    "    raise FileNotFoundError(f\"No FITS files found under {DATA_FOLDER.resolve()}\")\n",
    "\n",
    "name_to_label = {}\n",
    "if MANIFEST_CSV.exists():\n",
    "    manifest = pd.read_csv(MANIFEST_CSV)\n",
    "    keycol = \"productFilename\" if \"productFilename\" in manifest.columns else (\"filename\" if \"filename\" in manifest.columns else None)\n",
    "    if keycol is None:\n",
    "        raise ValueError(\"manifest.csv must have 'productFilename' or 'filename' column.\")\n",
    "\n",
    "    def row_to_label(row):\n",
    "        # Prefer explicit boolean-ish \"is_confirmed\"\n",
    "        ic = row.get(\"is_confirmed\", None)\n",
    "        if pd.notna(ic):\n",
    "            s = str(ic).strip().upper()\n",
    "            if s in (\"TRUE\", \"1\", \"YES\", \"Y\"):\n",
    "                return 1\n",
    "            if s in (\"FALSE\", \"0\", \"NO\", \"N\"):\n",
    "                return 0\n",
    "        # Fall back to disposition/status strings if present\n",
    "        disp = str(row.get(\"dispositions\", \"\")).upper()\n",
    "        stat = str(row.get(\"status_best\", \"\")).upper()\n",
    "        if \"CONFIRMED\" in disp or \"CONFIRMED\" in stat:\n",
    "            return 1\n",
    "        if \"FALSE POSITIVE\" in disp or \"FALSE POSITIVE\" in stat:\n",
    "            return 0\n",
    "        # default unlabeled → 0\n",
    "        return 0\n",
    "\n",
    "    manifest[\"label\"] = manifest.apply(row_to_label, axis=1)\n",
    "    # Map by just the basename to match f.name\n",
    "    name_to_label = dict(zip(manifest[keycol].astype(str).map(lambda p: Path(p).name),\n",
    "                             manifest[\"label\"].astype(int)))\n",
    "else:\n",
    "    warnings.warn(\"manifest.csv not found — defaulting all labels to 0 (not confirmed).\")\n",
    "    name_to_label = {}\n",
    "\n",
    "# --------------------------\n",
    "# Build feature table (with tqdm)\n",
    "# --------------------------\n",
    "rows, skips = [], 0\n",
    "for f in tqdm(fits_files, desc=\"Extracting features\", unit=\"file\"):\n",
    "    try:\n",
    "        feats = extract_features_from_fits(f)\n",
    "        label = int(name_to_label.get(f.name, 0))\n",
    "        feats.update(dict(filename=f.name, label=label))\n",
    "        rows.append(feats)\n",
    "    except Exception as e:\n",
    "        skips += 1\n",
    "        tqdm.write(f\"[SKIP] {f.name}: {e}\")\n",
    "\n",
    "if len(rows) < 2 or len({r['label'] for r in rows}) < 2:\n",
    "    print(\"[WARN] Not enough labeled variety; training may be trivial or fail. Check manifest labels.\")\n",
    "\n",
    "df = pd.DataFrame(rows).dropna(axis=1, how=\"all\")[:MAX_FILES]\n",
    "feature_cols = [c for c in df.columns if c not in (\"filename\", \"label\")]\n",
    "X = df[feature_cols].copy()\n",
    "# Median impute and cast to float\n",
    "X = X.fillna(X.median(numeric_only=True)).astype(float).values\n",
    "y = df[\"label\"].astype(int).values\n",
    "\n",
    "# --------------------------\n",
    "# Train / Valid split and LightGBM model\n",
    "# --------------------------\n",
    "# Keep test_size reasonable for very small datasets\n",
    "if len(y) > 10:\n",
    "    test_size = 0.3\n",
    "else:\n",
    "    test_size = 0.5\n",
    "\n",
    "stratify = y if len(np.unique(y)) > 1 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=RANDOM_SEED, stratify=stratify\n",
    ")\n",
    "\n",
    "train_ds = lgb.Dataset(X_train, label=y_train)\n",
    "valid_ds = lgb.Dataset(X_test, label=y_test, reference=train_ds)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"min_data_in_leaf\": 10,\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "booster = lgb.train(\n",
    "    params, train_ds, num_boost_round=1000,\n",
    "    valid_sets=[train_ds, valid_ds], valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(50)]\n",
    ")\n",
    "\n",
    "def predict_label(arr):\n",
    "    p = booster.predict(arr.reshape(1, -1), num_iteration=booster.best_iteration)[0]\n",
    "    return int(p >= 0.5), float(p)\n",
    "\n",
    "# Basic eval\n",
    "y_pred = (booster.predict(X_test, num_iteration=booster.best_iteration) >= 0.5).astype(int)\n",
    "print(\"\\n=== Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# --------------------------\n",
    "# White-box greedy attack (tree-path heuristic) + tqdm over iterations\n",
    "# --------------------------\n",
    "def _dump_model(booster):\n",
    "    return booster.dump_model()\n",
    "\n",
    "def _traverse_to_leaf(node, x):\n",
    "    path = []\n",
    "    nd = node\n",
    "    while 'leaf_index' not in nd:\n",
    "        path.append(nd)\n",
    "        fid = nd['split_feature']\n",
    "        thr = float(nd['threshold'])\n",
    "        nd = nd['left_child'] if x[fid] <= thr else nd['right_child']\n",
    "    path.append(nd)\n",
    "    return nd, path\n",
    "\n",
    "def _min_delta_to_flip(threshold, current_value, eps=1e-6):\n",
    "    # Smallest signed perturbation to cross the threshold\n",
    "    return (threshold + eps) - current_value if current_value <= threshold else (threshold - eps) - current_value\n",
    "\n",
    "def greedy_tree_attack(x0, target_label, booster, feature_bounds=None, max_iters=50, eps=1e-6, show_tqdm=True):\n",
    "    model = _dump_model(booster)\n",
    "    x = x0.copy().astype(float)\n",
    "    lo, hi = (None, None) if feature_bounds is None else feature_bounds\n",
    "\n",
    "    def prob1(z):\n",
    "        return float(booster.predict(z.reshape(1, -1), num_iteration=booster.best_iteration)[0])\n",
    "    def current_label(z):\n",
    "        p = prob1(z)\n",
    "        return (1 if p >= 0.5 else 0), p\n",
    "\n",
    "    y_cur, p_cur = current_label(x)\n",
    "    changes = []\n",
    "    best_x = x.copy()\n",
    "    best_p_for_target = p_cur if target_label == 1 else (1.0 - p_cur)\n",
    "\n",
    "    if y_cur == target_label:\n",
    "        return x, True, changes\n",
    "\n",
    "    it_iter = tqdm(range(max_iters), desc=\"Greedy attack\", unit=\"iter\", leave=False) if show_tqdm else range(max_iters)\n",
    "    for _ in it_iter:\n",
    "        candidates = []\n",
    "        for tree in model[\"tree_info\"]:\n",
    "            root = tree[\"tree_structure\"]\n",
    "            _, path_nodes = _traverse_to_leaf(root, x)\n",
    "            for node in path_nodes:\n",
    "                if 'split_index' not in node:\n",
    "                    continue\n",
    "                fidx = node['split_feature']\n",
    "                thr = float(node['threshold'])\n",
    "                cur_val = x[fidx]\n",
    "                delta = _min_delta_to_flip(thr, cur_val, eps=eps)\n",
    "                if abs(delta) < 1e-12:\n",
    "                    continue\n",
    "                new_val = cur_val + delta\n",
    "                if feature_bounds is not None:\n",
    "                    if not (lo[fidx] <= new_val <= hi[fidx]):\n",
    "                        continue\n",
    "                    new_val = float(np.clip(new_val, lo[fidx], hi[fidx]))\n",
    "                new_x = x.copy()\n",
    "                new_x[fidx] = new_val\n",
    "                _, new_p = current_label(new_x)\n",
    "                gain_for_target = new_p if target_label == 1 else (1.0 - new_p)\n",
    "                candidates.append((gain_for_target, abs(delta), fidx, new_val - cur_val, new_x, new_p))\n",
    "\n",
    "        if not candidates:\n",
    "            break\n",
    "\n",
    "        # Prefer best target-probability gain; tie-break by smaller move\n",
    "        candidates.sort(key=lambda t: (-t[0], t[1]))\n",
    "        gain, absd, fidx, delta, new_x, new_p = candidates[0]\n",
    "        x = new_x\n",
    "        changes.append((fidx, delta))\n",
    "\n",
    "        y_cur, p_cur = current_label(x)\n",
    "        score_for_target = p_cur if target_label == 1 else (1.0 - p_cur)\n",
    "        if score_for_target > best_p_for_target:\n",
    "            best_p_for_target = score_for_target\n",
    "            best_x = x.copy()\n",
    "\n",
    "        if y_cur == target_label:\n",
    "            return x, True, changes\n",
    "\n",
    "    final_label, _ = current_label(best_x)\n",
    "    return best_x, (final_label == target_label), changes\n",
    "\n",
    "# --------------------------\n",
    "# Choose a sample and attack\n",
    "# --------------------------\n",
    "if len(X_test) == 0:\n",
    "    raise RuntimeError(\"Empty test set; cannot run attack.\")\n",
    "\n",
    "neg_indices = np.where(y_test == 0)[0]\n",
    "if neg_indices.size == 0:\n",
    "    print(\"[INFO] No negative samples in test set; flipping a positive to negative instead.\")\n",
    "    idx = 0\n",
    "    desired = 0\n",
    "else:\n",
    "    idx = int(neg_indices[0])\n",
    "    desired = 1\n",
    "\n",
    "x0 = X_test[idx].copy()\n",
    "y0, p0 = predict_label(x0)\n",
    "\n",
    "# Per-feature bounds from training data (min/max)\n",
    "lo = np.nanmin(X_train, axis=0)\n",
    "hi = np.nanmax(X_train, axis=0)\n",
    "x_adv, success, changes = greedy_tree_attack(\n",
    "    x0, desired, booster, feature_bounds=(lo, hi), max_iters=200, show_tqdm=True\n",
    ")\n",
    "\n",
    "y1, p1 = predict_label(x_adv)\n",
    "\n",
    "# --------------------------\n",
    "# Report changes\n",
    "# --------------------------\n",
    "print(\"\\n=== Adversarial Attack Result ===\")\n",
    "print(f\"Original pred: {y0} (p1={p0:.4f})  →  Desired: {desired}\")\n",
    "print(f\"After attack:  {y1} (p1={p1:.4f})  | Success: {success}\")\n",
    "\n",
    "delta = x_adv - x0\n",
    "changed_idxs = np.where(np.abs(delta) > 1e-12)[0]\n",
    "if changed_idxs.size == 0:\n",
    "    print(\"No feature changed (already at desired class or no viable move).\")\n",
    "else:\n",
    "    print(\"\\nChanged features (feature_name : delta [percent of (max-min)]):\")\n",
    "    ranges = (hi - lo) + 1e-12\n",
    "    for fi in changed_idxs:\n",
    "        fname = feature_cols[fi]\n",
    "        d = float(delta[fi])\n",
    "        pct = 100.0 * (d / ranges[fi])\n",
    "        print(f\" - {fname:12s}: {d:+.6g}  [{pct:+.2f}% of range]\")\n",
    "\n",
    "# Context: top importances\n",
    "imp = booster.feature_importance(importance_type=\"gain\")\n",
    "imp_pairs = sorted(zip(feature_cols, imp), key=lambda t: -t[1])\n",
    "print(\"\\nTop feature importances (gain):\")\n",
    "for n, (fname, val) in enumerate(imp_pairs[:10], 1):\n",
    "    print(f\"{n:2d}. {fname:12s} : {val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35d504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
